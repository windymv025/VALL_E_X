2023-11-01 00:19:48,610 INFO [train.py:851] Training started
2023-11-01 00:19:48,611 INFO [train.py:870] Device: cuda:0
2023-11-01 00:19:48,611 INFO [train.py:871] {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 100, 'reset_interval': 200, 'valid_interval': 10000, 'world_size': 1, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 20, 'start_epoch': 1, 'start_batch': 0, 'exp_dir': PosixPath('exp/valle_dev'), 'optimizer_name': 'ScaledAdam', 'scheduler_name': 'Eden', 'base_lr': 0.005, 'warmup_steps': 200, 'seed': 42, 'inf_check': False, 'save_every_n': 10000, 'keep_last_k': 20, 'average_period': 0, 'accumulate_grad_steps': 1, 'dtype': 'float16', 'filter_min_duration': 0.0, 'filter_max_duration': 20.0, 'train_stage': 0, 'visualize': False, 'oom_check': True, 'train_dir': '/home/ubuntu/VALL-E-X/JS_Dataset/JS_Dataset/train_tune', 'valid_dir': '/home/ubuntu/VALL-E-X/JS_Dataset/JS_Dataset/valid_tune', 'model_name': 'VALL-E', 'decoder_dim': 1024, 'nhead': 16, 'num_decoder_layers': 12, 'scale_factor': 1.0, 'norm_first': True, 'add_prenet': False, 'prefix_mode': 0, 'share_embedding': True, 'prepend_bos': False, 'num_quantizers': 8, 'scaling_xformers': False}
2023-11-01 00:19:48,611 INFO [train.py:873] About to create model
2023-11-01 00:19:52,689 INFO [train.py:877] Number of model parameters: 370539524
2023-11-01 00:19:52,909 DEBUG [__init__.py:113] Building prefix dict from the default dictionary ...
2023-11-01 00:19:52,910 DEBUG [__init__.py:132] Loading model from cache /tmp/jieba.cache
2023-11-01 00:19:53,423 DEBUG [__init__.py:164] Loading model cost 0.513 seconds.
2023-11-01 00:19:53,423 DEBUG [__init__.py:166] Prefix dict has been built successfully.
2023-11-01 00:20:15,635 INFO [train.py:764] Epoch 1, batch 100, train_loss[loss=3.202, ArTop10Accuracy=0.7412, NarTop10Accuracy=0.6004, over 1306.00 frames. ], tot_loss[loss=3.398, ArTop10Accuracy=0.7055, NarTop10Accuracy=0.553, over 476.97 frames. ], batch size: 3, lr: 3.75e-03, grad_scale: 1.0
2023-11-01 00:20:37,125 INFO [train.py:764] Epoch 1, batch 200, train_loss[loss=3.531, ArTop10Accuracy=0.6921, NarTop10Accuracy=0.5406, over 1234.00 frames. ], tot_loss[loss=3.408, ArTop10Accuracy=0.7094, NarTop10Accuracy=0.5521, over 749.45 frames. ], batch size: 3, lr: 5.00e-03, grad_scale: 1.0
2023-11-01 00:20:59,073 INFO [train.py:764] Epoch 1, batch 300, train_loss[loss=3.609, ArTop10Accuracy=0.7015, NarTop10Accuracy=0.4503, over 995.00 frames. ], tot_loss[loss=3.443, ArTop10Accuracy=0.7109, NarTop10Accuracy=0.5387, over 935.67 frames. ], batch size: 2, lr: 5.00e-03, grad_scale: 1.0
2023-11-01 00:21:20,852 INFO [train.py:764] Epoch 1, batch 400, train_loss[loss=3.419, ArTop10Accuracy=0.6896, NarTop10Accuracy=0.5319, over 1234.00 frames. ], tot_loss[loss=3.463, ArTop10Accuracy=0.7133, NarTop10Accuracy=0.5285, over 1040.70 frames. ], batch size: 3, lr: 4.99e-03, grad_scale: 2.0
2023-11-01 00:21:42,406 INFO [train.py:764] Epoch 1, batch 500, train_loss[loss=3.293, ArTop10Accuracy=0.7238, NarTop10Accuracy=0.5892, over 1271.00 frames. ], tot_loss[loss=3.483, ArTop10Accuracy=0.7149, NarTop10Accuracy=0.5217, over 1094.80 frames. ], batch size: 3, lr: 4.99e-03, grad_scale: 2.0
2023-11-01 00:22:04,280 INFO [train.py:764] Epoch 1, batch 600, train_loss[loss=3.675, ArTop10Accuracy=0.7139, NarTop10Accuracy=0.4414, over 1496.00 frames. ], tot_loss[loss=3.461, ArTop10Accuracy=0.7191, NarTop10Accuracy=0.5267, over 1141.86 frames. ], batch size: 3, lr: 4.98e-03, grad_scale: 2.0
2023-11-01 00:22:25,961 INFO [train.py:764] Epoch 1, batch 700, train_loss[loss=3.25, ArTop10Accuracy=0.6822, NarTop10Accuracy=0.6536, over 1010.00 frames. ], tot_loss[loss=3.468, ArTop10Accuracy=0.7182, NarTop10Accuracy=0.5271, over 1167.56 frames. ], batch size: 2, lr: 4.98e-03, grad_scale: 2.0
2023-11-01 00:22:47,713 INFO [train.py:764] Epoch 1, batch 800, train_loss[loss=3.896, ArTop10Accuracy=0.6663, NarTop10Accuracy=0.4321, over 947.00 frames. ], tot_loss[loss=3.468, ArTop10Accuracy=0.7199, NarTop10Accuracy=0.5278, over 1184.08 frames. ], batch size: 2, lr: 4.97e-03, grad_scale: 4.0
2023-11-01 00:23:09,399 INFO [train.py:764] Epoch 1, batch 900, train_loss[loss=3.434, ArTop10Accuracy=0.7556, NarTop10Accuracy=0.5224, over 1195.00 frames. ], tot_loss[loss=3.461, ArTop10Accuracy=0.7214, NarTop10Accuracy=0.5295, over 1188.23 frames. ], batch size: 3, lr: 4.96e-03, grad_scale: 4.0
2023-11-01 00:23:31,117 INFO [train.py:764] Epoch 1, batch 1000, train_loss[loss=3.611, ArTop10Accuracy=0.7125, NarTop10Accuracy=0.5023, over 1339.00 frames. ], tot_loss[loss=3.458, ArTop10Accuracy=0.7229, NarTop10Accuracy=0.5286, over 1190.57 frames. ], batch size: 3, lr: 4.95e-03, grad_scale: 4.0
2023-11-01 00:23:31,281 INFO [utils.py:877] Clipping_scale=2.0, grad-norm quartiles 3.204e+01 4.529e+01 5.014e+01 5.593e+01 9.312e+01, threshold=1.003e+02, percent-clipped=0.0
2023-11-01 00:23:53,034 INFO [train.py:764] Epoch 1, batch 1100, train_loss[loss=3.754, ArTop10Accuracy=0.7051, NarTop10Accuracy=0.4622, over 1007.00 frames. ], tot_loss[loss=3.465, ArTop10Accuracy=0.7233, NarTop10Accuracy=0.5252, over 1194.69 frames. ], batch size: 2, lr: 4.94e-03, grad_scale: 4.0
2023-11-01 00:24:15,002 INFO [train.py:764] Epoch 1, batch 1200, train_loss[loss=3.233, ArTop10Accuracy=0.7508, NarTop10Accuracy=0.5991, over 1228.00 frames. ], tot_loss[loss=3.456, ArTop10Accuracy=0.7254, NarTop10Accuracy=0.5279, over 1198.98 frames. ], batch size: 3, lr: 4.93e-03, grad_scale: 8.0
2023-11-01 00:24:36,955 INFO [train.py:764] Epoch 1, batch 1300, train_loss[loss=3.365, ArTop10Accuracy=0.7287, NarTop10Accuracy=0.5916, over 1054.00 frames. ], tot_loss[loss=3.464, ArTop10Accuracy=0.7257, NarTop10Accuracy=0.5265, over 1202.37 frames. ], batch size: 2, lr: 4.92e-03, grad_scale: 8.0
2023-11-01 00:24:58,700 INFO [train.py:764] Epoch 1, batch 1400, train_loss[loss=3.458, ArTop10Accuracy=0.731, NarTop10Accuracy=0.5298, over 1301.00 frames. ], tot_loss[loss=3.474, ArTop10Accuracy=0.7271, NarTop10Accuracy=0.5209, over 1198.94 frames. ], batch size: 3, lr: 4.91e-03, grad_scale: 8.0
2023-11-01 00:25:20,642 INFO [train.py:764] Epoch 1, batch 1500, train_loss[loss=3.331, ArTop10Accuracy=0.7508, NarTop10Accuracy=0.5712, over 1236.00 frames. ], tot_loss[loss=3.46, ArTop10Accuracy=0.7278, NarTop10Accuracy=0.5248, over 1198.26 frames. ], batch size: 3, lr: 4.89e-03, grad_scale: 8.0
2023-11-01 00:25:42,599 INFO [train.py:764] Epoch 1, batch 1600, train_loss[loss=3.627, ArTop10Accuracy=0.7136, NarTop10Accuracy=0.4668, over 1201.00 frames. ], tot_loss[loss=3.463, ArTop10Accuracy=0.7265, NarTop10Accuracy=0.5249, over 1204.65 frames. ], batch size: 3, lr: 4.88e-03, grad_scale: 8.0
2023-11-01 00:26:04,490 INFO [train.py:764] Epoch 1, batch 1700, train_loss[loss=3.399, ArTop10Accuracy=0.7477, NarTop10Accuracy=0.5198, over 650.00 frames. ], tot_loss[loss=3.46, ArTop10Accuracy=0.7275, NarTop10Accuracy=0.5243, over 1202.22 frames. ], batch size: 1, lr: 4.87e-03, grad_scale: 8.0
2023-11-01 00:26:26,353 INFO [train.py:764] Epoch 1, batch 1800, train_loss[loss=3.566, ArTop10Accuracy=0.7215, NarTop10Accuracy=0.4575, over 1253.00 frames. ], tot_loss[loss=3.46, ArTop10Accuracy=0.7281, NarTop10Accuracy=0.5244, over 1198.05 frames. ], batch size: 3, lr: 4.85e-03, grad_scale: 8.0
2023-11-01 00:26:48,377 INFO [train.py:764] Epoch 1, batch 1900, train_loss[loss=3.387, ArTop10Accuracy=0.8449, NarTop10Accuracy=0.4865, over 819.00 frames. ], tot_loss[loss=3.453, ArTop10Accuracy=0.7281, NarTop10Accuracy=0.527, over 1198.59 frames. ], batch size: 1, lr: 4.83e-03, grad_scale: 8.0
2023-11-01 00:27:10,331 INFO [train.py:764] Epoch 1, batch 2000, train_loss[loss=3.325, ArTop10Accuracy=0.7224, NarTop10Accuracy=0.5816, over 1286.00 frames. ], tot_loss[loss=3.442, ArTop10Accuracy=0.7305, NarTop10Accuracy=0.5298, over 1193.18 frames. ], batch size: 3, lr: 4.82e-03, grad_scale: 16.0
2023-11-01 00:27:10,506 INFO [utils.py:877] Clipping_scale=2.0, grad-norm quartiles 2.916e+01 4.003e+01 4.277e+01 4.588e+01 1.290e+02, threshold=8.555e+01, percent-clipped=0.1
2023-11-01 00:27:32,462 INFO [train.py:764] Epoch 1, batch 2100, train_loss[loss=3.532, ArTop10Accuracy=0.7298, NarTop10Accuracy=0.5061, over 1114.00 frames. ], tot_loss[loss=3.458, ArTop10Accuracy=0.7291, NarTop10Accuracy=0.5252, over 1201.39 frames. ], batch size: 2, lr: 4.80e-03, grad_scale: 16.0
2023-11-01 00:27:54,843 INFO [train.py:764] Epoch 1, batch 2200, train_loss[loss=3.206, ArTop10Accuracy=0.8044, NarTop10Accuracy=0.5327, over 1084.00 frames. ], tot_loss[loss=3.452, ArTop10Accuracy=0.7295, NarTop10Accuracy=0.5281, over 1212.86 frames. ], batch size: 2, lr: 4.78e-03, grad_scale: 16.0
2023-11-01 00:28:17,007 INFO [train.py:764] Epoch 1, batch 2300, train_loss[loss=3.656, ArTop10Accuracy=0.7355, NarTop10Accuracy=0.4183, over 1478.00 frames. ], tot_loss[loss=3.457, ArTop10Accuracy=0.729, NarTop10Accuracy=0.525, over 1212.39 frames. ], batch size: 3, lr: 4.77e-03, grad_scale: 16.0
2023-11-01 00:28:39,010 INFO [train.py:764] Epoch 1, batch 2400, train_loss[loss=3.578, ArTop10Accuracy=0.7343, NarTop10Accuracy=0.4818, over 1325.00 frames. ], tot_loss[loss=3.43, ArTop10Accuracy=0.7311, NarTop10Accuracy=0.5341, over 1209.83 frames. ], batch size: 3, lr: 4.75e-03, grad_scale: 16.0
2023-11-01 00:29:00,770 INFO [train.py:764] Epoch 1, batch 2500, train_loss[loss=3.153, ArTop10Accuracy=0.7836, NarTop10Accuracy=0.6147, over 1280.00 frames. ], tot_loss[loss=3.419, ArTop10Accuracy=0.7334, NarTop10Accuracy=0.5348, over 1200.35 frames. ], batch size: 3, lr: 4.73e-03, grad_scale: 16.0
2023-11-01 00:29:22,695 INFO [train.py:764] Epoch 1, batch 2600, train_loss[loss=3.217, ArTop10Accuracy=0.7502, NarTop10Accuracy=0.5967, over 1321.00 frames. ], tot_loss[loss=3.417, ArTop10Accuracy=0.7336, NarTop10Accuracy=0.5363, over 1203.85 frames. ], batch size: 3, lr: 4.71e-03, grad_scale: 16.0
2023-11-01 00:29:44,570 INFO [train.py:764] Epoch 1, batch 2700, train_loss[loss=3.181, ArTop10Accuracy=0.7385, NarTop10Accuracy=0.624, over 1480.00 frames. ], tot_loss[loss=3.406, ArTop10Accuracy=0.7344, NarTop10Accuracy=0.5392, over 1201.18 frames. ], batch size: 3, lr: 4.69e-03, grad_scale: 16.0
2023-11-01 00:30:06,497 INFO [train.py:764] Epoch 1, batch 2800, train_loss[loss=3.198, ArTop10Accuracy=0.734, NarTop10Accuracy=0.6348, over 1297.00 frames. ], tot_loss[loss=3.411, ArTop10Accuracy=0.7353, NarTop10Accuracy=0.5371, over 1201.74 frames. ], batch size: 3, lr: 4.67e-03, grad_scale: 16.0
2023-11-01 00:30:28,351 INFO [train.py:764] Epoch 1, batch 2900, train_loss[loss=3.037, ArTop10Accuracy=0.7592, NarTop10Accuracy=0.6745, over 1387.00 frames. ], tot_loss[loss=3.422, ArTop10Accuracy=0.7355, NarTop10Accuracy=0.5335, over 1199.06 frames. ], batch size: 3, lr: 4.65e-03, grad_scale: 16.0
2023-11-01 00:30:50,226 INFO [train.py:764] Epoch 1, batch 3000, train_loss[loss=3.231, ArTop10Accuracy=0.7304, NarTop10Accuracy=0.6256, over 1261.00 frames. ], tot_loss[loss=3.429, ArTop10Accuracy=0.7346, NarTop10Accuracy=0.5312, over 1193.63 frames. ], batch size: 3, lr: 4.63e-03, grad_scale: 16.0
2023-11-01 00:30:50,404 INFO [utils.py:877] Clipping_scale=2.0, grad-norm quartiles 2.518e+01 3.788e+01 4.043e+01 4.342e+01 9.222e+01, threshold=8.086e+01, percent-clipped=0.2
2023-11-01 00:31:12,558 INFO [train.py:764] Epoch 1, batch 3100, train_loss[loss=3.228, ArTop10Accuracy=0.7206, NarTop10Accuracy=0.6731, over 1070.00 frames. ], tot_loss[loss=3.421, ArTop10Accuracy=0.7344, NarTop10Accuracy=0.5346, over 1195.52 frames. ], batch size: 2, lr: 4.61e-03, grad_scale: 16.0
2023-11-01 00:31:34,821 INFO [train.py:764] Epoch 1, batch 3200, train_loss[loss=3.373, ArTop10Accuracy=0.7137, NarTop10Accuracy=0.5737, over 1289.00 frames. ], tot_loss[loss=3.418, ArTop10Accuracy=0.7353, NarTop10Accuracy=0.5343, over 1210.89 frames. ], batch size: 3, lr: 4.59e-03, grad_scale: 16.0
2023-11-01 00:31:56,704 INFO [train.py:764] Epoch 1, batch 3300, train_loss[loss=3.731, ArTop10Accuracy=0.7498, NarTop10Accuracy=0.4016, over 1331.00 frames. ], tot_loss[loss=3.428, ArTop10Accuracy=0.736, NarTop10Accuracy=0.5316, over 1199.90 frames. ], batch size: 3, lr: 4.57e-03, grad_scale: 16.0
2023-11-01 00:32:18,676 INFO [train.py:764] Epoch 1, batch 3400, train_loss[loss=3.212, ArTop10Accuracy=0.7604, NarTop10Accuracy=0.6446, over 1223.00 frames. ], tot_loss[loss=3.424, ArTop10Accuracy=0.737, NarTop10Accuracy=0.531, over 1204.36 frames. ], batch size: 3, lr: 4.55e-03, grad_scale: 16.0
2023-11-01 00:32:40,608 INFO [train.py:764] Epoch 1, batch 3500, train_loss[loss=3.223, ArTop10Accuracy=0.7422, NarTop10Accuracy=0.6264, over 1315.00 frames. ], tot_loss[loss=3.418, ArTop10Accuracy=0.7374, NarTop10Accuracy=0.5322, over 1203.43 frames. ], batch size: 3, lr: 4.53e-03, grad_scale: 16.0
2023-11-01 00:33:02,672 INFO [train.py:764] Epoch 1, batch 3600, train_loss[loss=3.237, ArTop10Accuracy=0.7415, NarTop10Accuracy=0.5996, over 1002.00 frames. ], tot_loss[loss=3.411, ArTop10Accuracy=0.7378, NarTop10Accuracy=0.5369, over 1200.89 frames. ], batch size: 2, lr: 4.50e-03, grad_scale: 16.0
2023-11-01 00:33:24,593 INFO [train.py:764] Epoch 1, batch 3700, train_loss[loss=3.049, ArTop10Accuracy=0.7433, NarTop10Accuracy=0.6294, over 1270.00 frames. ], tot_loss[loss=3.404, ArTop10Accuracy=0.7378, NarTop10Accuracy=0.5378, over 1199.71 frames. ], batch size: 3, lr: 4.48e-03, grad_scale: 16.0
2023-11-01 00:33:46,541 INFO [train.py:764] Epoch 1, batch 3800, train_loss[loss=3.443, ArTop10Accuracy=0.7345, NarTop10Accuracy=0.5163, over 953.00 frames. ], tot_loss[loss=3.423, ArTop10Accuracy=0.737, NarTop10Accuracy=0.5303, over 1206.54 frames. ], batch size: 2, lr: 4.46e-03, grad_scale: 16.0
2023-11-01 00:34:08,561 INFO [train.py:764] Epoch 1, batch 3900, train_loss[loss=3.271, ArTop10Accuracy=0.7608, NarTop10Accuracy=0.5504, over 1346.00 frames. ], tot_loss[loss=3.408, ArTop10Accuracy=0.7383, NarTop10Accuracy=0.5361, over 1214.09 frames. ], batch size: 3, lr: 4.44e-03, grad_scale: 16.0
2023-11-01 00:34:30,421 INFO [train.py:764] Epoch 1, batch 4000, train_loss[loss=3.177, ArTop10Accuracy=0.7882, NarTop10Accuracy=0.6005, over 1336.00 frames. ], tot_loss[loss=3.396, ArTop10Accuracy=0.739, NarTop10Accuracy=0.5396, over 1202.95 frames. ], batch size: 3, lr: 4.42e-03, grad_scale: 32.0
2023-11-01 00:34:30,586 INFO [utils.py:877] Clipping_scale=2.0, grad-norm quartiles 2.781e+01 3.743e+01 4.001e+01 4.276e+01 1.199e+02, threshold=8.003e+01, percent-clipped=0.2
2023-11-01 00:34:52,163 INFO [train.py:764] Epoch 1, batch 4100, train_loss[loss=3.238, ArTop10Accuracy=0.74, NarTop10Accuracy=0.5985, over 1277.00 frames. ], tot_loss[loss=3.4, ArTop10Accuracy=0.7395, NarTop10Accuracy=0.5383, over 1197.35 frames. ], batch size: 3, lr: 4.40e-03, grad_scale: 32.0
2023-11-01 00:35:14,150 INFO [train.py:764] Epoch 1, batch 4200, train_loss[loss=3.329, ArTop10Accuracy=0.737, NarTop10Accuracy=0.5832, over 1228.00 frames. ], tot_loss[loss=3.395, ArTop10Accuracy=0.7388, NarTop10Accuracy=0.5409, over 1204.03 frames. ], batch size: 3, lr: 4.38e-03, grad_scale: 32.0
2023-11-01 00:35:36,263 INFO [train.py:764] Epoch 1, batch 4300, train_loss[loss=3.293, ArTop10Accuracy=0.7733, NarTop10Accuracy=0.5665, over 1125.00 frames. ], tot_loss[loss=3.393, ArTop10Accuracy=0.7399, NarTop10Accuracy=0.5412, over 1201.24 frames. ], batch size: 1, lr: 4.35e-03, grad_scale: 32.0
2023-11-01 00:35:58,283 INFO [train.py:764] Epoch 1, batch 4400, train_loss[loss=2.99, ArTop10Accuracy=0.7618, NarTop10Accuracy=0.7263, over 1297.00 frames. ], tot_loss[loss=3.387, ArTop10Accuracy=0.7425, NarTop10Accuracy=0.5403, over 1202.84 frames. ], batch size: 3, lr: 4.33e-03, grad_scale: 32.0
2023-11-01 00:36:20,271 INFO [train.py:764] Epoch 1, batch 4500, train_loss[loss=3.166, ArTop10Accuracy=0.7474, NarTop10Accuracy=0.6354, over 1271.00 frames. ], tot_loss[loss=3.375, ArTop10Accuracy=0.7434, NarTop10Accuracy=0.5462, over 1206.43 frames. ], batch size: 3, lr: 4.31e-03, grad_scale: 32.0
2023-11-01 00:36:42,281 INFO [train.py:764] Epoch 1, batch 4600, train_loss[loss=3.479, ArTop10Accuracy=0.7316, NarTop10Accuracy=0.5057, over 980.00 frames. ], tot_loss[loss=3.377, ArTop10Accuracy=0.7436, NarTop10Accuracy=0.5457, over 1199.69 frames. ], batch size: 2, lr: 4.29e-03, grad_scale: 32.0
2023-11-01 00:37:04,337 INFO [train.py:764] Epoch 1, batch 4700, train_loss[loss=3.177, ArTop10Accuracy=0.7289, NarTop10Accuracy=0.6232, over 1280.00 frames. ], tot_loss[loss=3.378, ArTop10Accuracy=0.7425, NarTop10Accuracy=0.5457, over 1200.61 frames. ], batch size: 3, lr: 4.27e-03, grad_scale: 32.0
2023-11-01 00:37:26,359 INFO [train.py:764] Epoch 1, batch 4800, train_loss[loss=3.718, ArTop10Accuracy=0.7287, NarTop10Accuracy=0.4516, over 1176.00 frames. ], tot_loss[loss=3.384, ArTop10Accuracy=0.7417, NarTop10Accuracy=0.5444, over 1204.83 frames. ], batch size: 2, lr: 4.25e-03, grad_scale: 32.0
2023-11-01 00:37:48,245 INFO [train.py:764] Epoch 1, batch 4900, train_loss[loss=3.189, ArTop10Accuracy=0.7412, NarTop10Accuracy=0.6122, over 962.00 frames. ], tot_loss[loss=3.395, ArTop10Accuracy=0.7405, NarTop10Accuracy=0.5393, over 1196.82 frames. ], batch size: 2, lr: 4.23e-03, grad_scale: 32.0
2023-11-01 00:38:10,398 INFO [train.py:764] Epoch 1, batch 5000, train_loss[loss=3.969, ArTop10Accuracy=0.6697, NarTop10Accuracy=0.3746, over 1002.00 frames. ], tot_loss[loss=3.4, ArTop10Accuracy=0.7401, NarTop10Accuracy=0.5376, over 1198.57 frames. ], batch size: 2, lr: 4.20e-03, grad_scale: 32.0
2023-11-01 00:38:10,556 INFO [utils.py:877] Clipping_scale=2.0, grad-norm quartiles 2.722e+01 3.674e+01 3.909e+01 4.182e+01 1.163e+02, threshold=7.817e+01, percent-clipped=0.1
2023-11-01 00:38:32,372 INFO [train.py:764] Epoch 1, batch 5100, train_loss[loss=3.425, ArTop10Accuracy=0.7333, NarTop10Accuracy=0.535, over 1050.00 frames. ], tot_loss[loss=3.389, ArTop10Accuracy=0.7421, NarTop10Accuracy=0.5403, over 1202.12 frames. ], batch size: 2, lr: 4.18e-03, grad_scale: 32.0
2023-11-01 00:38:54,235 INFO [train.py:764] Epoch 1, batch 5200, train_loss[loss=3.11, ArTop10Accuracy=0.7507, NarTop10Accuracy=0.6442, over 1352.00 frames. ], tot_loss[loss=3.382, ArTop10Accuracy=0.7421, NarTop10Accuracy=0.5436, over 1199.90 frames. ], batch size: 3, lr: 4.16e-03, grad_scale: 32.0
2023-11-01 00:39:15,969 INFO [train.py:764] Epoch 1, batch 5300, train_loss[loss=3.178, ArTop10Accuracy=0.756, NarTop10Accuracy=0.5823, over 1217.00 frames. ], tot_loss[loss=3.4, ArTop10Accuracy=0.7417, NarTop10Accuracy=0.5379, over 1195.55 frames. ], batch size: 3, lr: 4.14e-03, grad_scale: 32.0
2023-11-01 00:39:37,856 INFO [train.py:764] Epoch 1, batch 5400, train_loss[loss=3.272, ArTop10Accuracy=0.7515, NarTop10Accuracy=0.5808, over 1300.00 frames. ], tot_loss[loss=3.385, ArTop10Accuracy=0.7428, NarTop10Accuracy=0.5426, over 1202.33 frames. ], batch size: 3, lr: 4.12e-03, grad_scale: 32.0
2023-11-01 00:39:59,844 INFO [train.py:764] Epoch 1, batch 5500, train_loss[loss=3.962, ArTop10Accuracy=0.7026, NarTop10Accuracy=0.362, over 1318.00 frames. ], tot_loss[loss=3.393, ArTop10Accuracy=0.7416, NarTop10Accuracy=0.5403, over 1204.76 frames. ], batch size: 3, lr: 4.10e-03, grad_scale: 32.0
2023-11-01 00:40:21,881 INFO [train.py:764] Epoch 1, batch 5600, train_loss[loss=3.23, ArTop10Accuracy=0.7509, NarTop10Accuracy=0.6012, over 1064.00 frames. ], tot_loss[loss=3.389, ArTop10Accuracy=0.742, NarTop10Accuracy=0.5422, over 1209.03 frames. ], batch size: 2, lr: 4.08e-03, grad_scale: 32.0
2023-11-01 00:40:44,136 INFO [train.py:764] Epoch 1, batch 5700, train_loss[loss=3.756, ArTop10Accuracy=0.7013, NarTop10Accuracy=0.43, over 1309.00 frames. ], tot_loss[loss=3.404, ArTop10Accuracy=0.7411, NarTop10Accuracy=0.5373, over 1206.83 frames. ], batch size: 3, lr: 4.06e-03, grad_scale: 32.0
2023-11-01 00:41:06,015 INFO [train.py:764] Epoch 1, batch 5800, train_loss[loss=3.22, ArTop10Accuracy=0.7976, NarTop10Accuracy=0.5996, over 1077.00 frames. ], tot_loss[loss=3.393, ArTop10Accuracy=0.7424, NarTop10Accuracy=0.5391, over 1198.69 frames. ], batch size: 2, lr: 4.04e-03, grad_scale: 32.0
2023-11-01 00:41:27,922 INFO [train.py:764] Epoch 1, batch 5900, train_loss[loss=3.255, ArTop10Accuracy=0.7603, NarTop10Accuracy=0.5729, over 1410.00 frames. ], tot_loss[loss=3.379, ArTop10Accuracy=0.7444, NarTop10Accuracy=0.5428, over 1195.35 frames. ], batch size: 2, lr: 4.02e-03, grad_scale: 32.0
2023-11-01 00:41:49,781 INFO [train.py:764] Epoch 1, batch 6000, train_loss[loss=3.04, ArTop10Accuracy=0.754, NarTop10Accuracy=0.6513, over 1264.00 frames. ], tot_loss[loss=3.367, ArTop10Accuracy=0.7448, NarTop10Accuracy=0.549, over 1191.87 frames. ], batch size: 3, lr: 4.00e-03, grad_scale: 64.0
2023-11-01 00:41:49,950 INFO [utils.py:877] Clipping_scale=2.0, grad-norm quartiles 3.018e+01 3.667e+01 3.892e+01 4.174e+01 9.103e+01, threshold=7.785e+01, percent-clipped=0.2
2023-11-01 00:42:11,871 INFO [train.py:764] Epoch 1, batch 6100, train_loss[loss=3.224, ArTop10Accuracy=0.7514, NarTop10Accuracy=0.5748, over 1275.00 frames. ], tot_loss[loss=3.365, ArTop10Accuracy=0.7445, NarTop10Accuracy=0.5489, over 1200.31 frames. ], batch size: 3, lr: 3.98e-03, grad_scale: 64.0
2023-11-01 00:42:33,790 INFO [train.py:764] Epoch 1, batch 6200, train_loss[loss=3.631, ArTop10Accuracy=0.7441, NarTop10Accuracy=0.4927, over 1067.00 frames. ], tot_loss[loss=3.368, ArTop10Accuracy=0.7456, NarTop10Accuracy=0.5473, over 1197.29 frames. ], batch size: 2, lr: 3.96e-03, grad_scale: 64.0
2023-11-01 00:42:55,647 INFO [train.py:764] Epoch 1, batch 6300, train_loss[loss=2.863, ArTop10Accuracy=0.7722, NarTop10Accuracy=0.6714, over 1229.00 frames. ], tot_loss[loss=3.358, ArTop10Accuracy=0.7464, NarTop10Accuracy=0.549, over 1195.66 frames. ], batch size: 3, lr: 3.94e-03, grad_scale: 64.0
2023-11-01 00:43:17,732 INFO [train.py:764] Epoch 1, batch 6400, train_loss[loss=3.313, ArTop10Accuracy=0.7168, NarTop10Accuracy=0.6248, over 1342.00 frames. ], tot_loss[loss=3.364, ArTop10Accuracy=0.7454, NarTop10Accuracy=0.5488, over 1200.90 frames. ], batch size: 3, lr: 3.92e-03, grad_scale: 16.0
2023-11-01 00:43:39,683 INFO [train.py:764] Epoch 1, batch 6500, train_loss[loss=3.58, ArTop10Accuracy=0.7492, NarTop10Accuracy=0.4578, over 1324.00 frames. ], tot_loss[loss=3.365, ArTop10Accuracy=0.7452, NarTop10Accuracy=0.5472, over 1203.64 frames. ], batch size: 3, lr: 3.90e-03, grad_scale: 16.0
2023-11-01 00:44:01,658 INFO [train.py:764] Epoch 1, batch 6600, train_loss[loss=3.618, ArTop10Accuracy=0.7234, NarTop10Accuracy=0.4793, over 1157.00 frames. ], tot_loss[loss=3.375, ArTop10Accuracy=0.7447, NarTop10Accuracy=0.5439, over 1199.80 frames. ], batch size: 2, lr: 3.89e-03, grad_scale: 16.0
2023-11-01 00:44:23,811 INFO [train.py:764] Epoch 1, batch 6700, train_loss[loss=3.909, ArTop10Accuracy=0.7282, NarTop10Accuracy=0.3605, over 1512.00 frames. ], tot_loss[loss=3.374, ArTop10Accuracy=0.747, NarTop10Accuracy=0.5432, over 1206.18 frames. ], batch size: 2, lr: 3.87e-03, grad_scale: 16.0
2023-11-01 00:44:45,778 INFO [train.py:764] Epoch 1, batch 6800, train_loss[loss=3.756, ArTop10Accuracy=0.6656, NarTop10Accuracy=0.4652, over 1250.00 frames. ], tot_loss[loss=3.378, ArTop10Accuracy=0.7473, NarTop10Accuracy=0.5408, over 1211.75 frames. ], batch size: 3, lr: 3.85e-03, grad_scale: 16.0
2023-11-01 00:45:07,536 INFO [train.py:764] Epoch 1, batch 6900, train_loss[loss=3.302, ArTop10Accuracy=0.7848, NarTop10Accuracy=0.5048, over 1199.00 frames. ], tot_loss[loss=3.369, ArTop10Accuracy=0.7478, NarTop10Accuracy=0.5444, over 1203.83 frames. ], batch size: 3, lr: 3.83e-03, grad_scale: 16.0
2023-11-01 00:45:29,567 INFO [train.py:764] Epoch 1, batch 7000, train_loss[loss=3.614, ArTop10Accuracy=0.667, NarTop10Accuracy=0.5579, over 1054.00 frames. ], tot_loss[loss=3.379, ArTop10Accuracy=0.7464, NarTop10Accuracy=0.5433, over 1205.70 frames. ], batch size: 2, lr: 3.81e-03, grad_scale: 16.0
2023-11-01 00:45:30,189 INFO [utils.py:877] Clipping_scale=2.0, grad-norm quartiles 2.893e+01 3.646e+01 3.891e+01 4.178e+01 1.168e+02, threshold=7.782e+01, percent-clipped=0.2
2023-11-01 00:45:51,356 INFO [train.py:764] Epoch 1, batch 7100, train_loss[loss=3.365, ArTop10Accuracy=0.7592, NarTop10Accuracy=0.539, over 1221.00 frames. ], tot_loss[loss=3.363, ArTop10Accuracy=0.7483, NarTop10Accuracy=0.5466, over 1200.17 frames. ], batch size: 3, lr: 3.79e-03, grad_scale: 16.0
2023-11-01 00:46:13,329 INFO [train.py:764] Epoch 1, batch 7200, train_loss[loss=3.422, ArTop10Accuracy=0.7782, NarTop10Accuracy=0.5144, over 1109.00 frames. ], tot_loss[loss=3.349, ArTop10Accuracy=0.7504, NarTop10Accuracy=0.5512, over 1200.81 frames. ], batch size: 2, lr: 3.78e-03, grad_scale: 16.0
2023-11-01 00:46:35,352 INFO [train.py:764] Epoch 1, batch 7300, train_loss[loss=3.123, ArTop10Accuracy=0.7526, NarTop10Accuracy=0.6595, over 1047.00 frames. ], tot_loss[loss=3.357, ArTop10Accuracy=0.7506, NarTop10Accuracy=0.549, over 1199.39 frames. ], batch size: 2, lr: 3.76e-03, grad_scale: 16.0
2023-11-01 00:46:57,454 INFO [train.py:764] Epoch 1, batch 7400, train_loss[loss=3.457, ArTop10Accuracy=0.7662, NarTop10Accuracy=0.4982, over 1142.00 frames. ], tot_loss[loss=3.35, ArTop10Accuracy=0.7506, NarTop10Accuracy=0.552, over 1204.30 frames. ], batch size: 2, lr: 3.74e-03, grad_scale: 16.0
2023-11-01 00:47:19,658 INFO [train.py:764] Epoch 1, batch 7500, train_loss[loss=3.83, ArTop10Accuracy=0.6948, NarTop10Accuracy=0.4401, over 1019.00 frames. ], tot_loss[loss=3.359, ArTop10Accuracy=0.7496, NarTop10Accuracy=0.5494, over 1211.85 frames. ], batch size: 2, lr: 3.72e-03, grad_scale: 16.0
2023-11-01 00:47:41,652 INFO [train.py:764] Epoch 1, batch 7600, train_loss[loss=3.049, ArTop10Accuracy=0.7516, NarTop10Accuracy=0.6564, over 1538.00 frames. ], tot_loss[loss=3.346, ArTop10Accuracy=0.7518, NarTop10Accuracy=0.5516, over 1203.46 frames. ], batch size: 3, lr: 3.71e-03, grad_scale: 16.0
2023-11-01 00:48:03,855 INFO [train.py:764] Epoch 1, batch 7700, train_loss[loss=3.38, ArTop10Accuracy=0.7527, NarTop10Accuracy=0.5145, over 1500.00 frames. ], tot_loss[loss=3.343, ArTop10Accuracy=0.7512, NarTop10Accuracy=0.553, over 1210.10 frames. ], batch size: 3, lr: 3.69e-03, grad_scale: 16.0
2023-11-01 00:48:25,842 INFO [train.py:764] Epoch 1, batch 7800, train_loss[loss=3.577, ArTop10Accuracy=0.7123, NarTop10Accuracy=0.5032, over 1300.00 frames. ], tot_loss[loss=3.344, ArTop10Accuracy=0.7498, NarTop10Accuracy=0.5536, over 1207.39 frames. ], batch size: 3, lr: 3.67e-03, grad_scale: 16.0
2023-11-01 00:48:47,914 INFO [train.py:764] Epoch 1, batch 7900, train_loss[loss=3.129, ArTop10Accuracy=0.7551, NarTop10Accuracy=0.6453, over 1323.00 frames. ], tot_loss[loss=3.348, ArTop10Accuracy=0.7489, NarTop10Accuracy=0.5529, over 1205.69 frames. ], batch size: 3, lr: 3.66e-03, grad_scale: 16.0
2023-11-01 00:49:10,108 INFO [train.py:764] Epoch 1, batch 8000, train_loss[loss=3.435, ArTop10Accuracy=0.7504, NarTop10Accuracy=0.5231, over 1314.00 frames. ], tot_loss[loss=3.344, ArTop10Accuracy=0.7484, NarTop10Accuracy=0.5538, over 1204.55 frames. ], batch size: 2, lr: 3.64e-03, grad_scale: 16.0
2023-11-01 00:49:10,719 INFO [utils.py:877] Clipping_scale=2.0, grad-norm quartiles 2.574e+01 3.623e+01 3.864e+01 4.175e+01 9.270e+01, threshold=7.727e+01, percent-clipped=0.3
2023-11-01 00:49:32,315 INFO [train.py:764] Epoch 1, batch 8100, train_loss[loss=3.578, ArTop10Accuracy=0.7281, NarTop10Accuracy=0.5042, over 1453.00 frames. ], tot_loss[loss=3.369, ArTop10Accuracy=0.7464, NarTop10Accuracy=0.5469, over 1201.98 frames. ], batch size: 3, lr: 3.62e-03, grad_scale: 16.0
2023-11-01 00:49:54,412 INFO [train.py:764] Epoch 1, batch 8200, train_loss[loss=3.126, ArTop10Accuracy=0.7671, NarTop10Accuracy=0.6341, over 1198.00 frames. ], tot_loss[loss=3.377, ArTop10Accuracy=0.7451, NarTop10Accuracy=0.5455, over 1201.66 frames. ], batch size: 3, lr: 3.61e-03, grad_scale: 16.0
2023-11-01 00:50:16,462 INFO [train.py:764] Epoch 1, batch 8300, train_loss[loss=3.51, ArTop10Accuracy=0.7526, NarTop10Accuracy=0.4518, over 1354.00 frames. ], tot_loss[loss=3.363, ArTop10Accuracy=0.7486, NarTop10Accuracy=0.546, over 1200.11 frames. ], batch size: 3, lr: 3.59e-03, grad_scale: 16.0
2023-11-01 00:50:38,610 INFO [train.py:764] Epoch 1, batch 8400, train_loss[loss=3.781, ArTop10Accuracy=0.7058, NarTop10Accuracy=0.4102, over 1064.00 frames. ], tot_loss[loss=3.363, ArTop10Accuracy=0.7496, NarTop10Accuracy=0.545, over 1201.74 frames. ], batch size: 2, lr: 3.58e-03, grad_scale: 32.0
2023-11-01 00:51:00,590 INFO [train.py:764] Epoch 1, batch 8500, train_loss[loss=3.679, ArTop10Accuracy=0.72, NarTop10Accuracy=0.4794, over 1082.00 frames. ], tot_loss[loss=3.357, ArTop10Accuracy=0.7495, NarTop10Accuracy=0.5478, over 1189.28 frames. ], batch size: 2, lr: 3.56e-03, grad_scale: 32.0
2023-11-01 00:51:22,638 INFO [train.py:764] Epoch 1, batch 8600, train_loss[loss=3.35, ArTop10Accuracy=0.7558, NarTop10Accuracy=0.5426, over 1208.00 frames. ], tot_loss[loss=3.361, ArTop10Accuracy=0.7485, NarTop10Accuracy=0.546, over 1195.17 frames. ], batch size: 3, lr: 3.54e-03, grad_scale: 32.0
2023-11-01 00:51:44,857 INFO [train.py:764] Epoch 1, batch 8700, train_loss[loss=3.502, ArTop10Accuracy=0.7509, NarTop10Accuracy=0.4911, over 1076.00 frames. ], tot_loss[loss=3.341, ArTop10Accuracy=0.7513, NarTop10Accuracy=0.5539, over 1199.46 frames. ], batch size: 2, lr: 3.53e-03, grad_scale: 32.0
2023-11-01 00:52:06,705 INFO [train.py:764] Epoch 1, batch 8800, train_loss[loss=3.171, ArTop10Accuracy=0.7301, NarTop10Accuracy=0.6783, over 1178.00 frames. ], tot_loss[loss=3.339, ArTop10Accuracy=0.751, NarTop10Accuracy=0.5542, over 1196.85 frames. ], batch size: 3, lr: 3.51e-03, grad_scale: 16.0
2023-11-01 00:52:28,687 INFO [train.py:764] Epoch 1, batch 8900, train_loss[loss=3.443, ArTop10Accuracy=0.7263, NarTop10Accuracy=0.5612, over 1330.00 frames. ], tot_loss[loss=3.333, ArTop10Accuracy=0.7516, NarTop10Accuracy=0.5562, over 1197.63 frames. ], batch size: 3, lr: 3.50e-03, grad_scale: 16.0
2023-11-01 00:52:50,763 INFO [train.py:764] Epoch 1, batch 9000, train_loss[loss=3.046, ArTop10Accuracy=0.7712, NarTop10Accuracy=0.6817, over 1355.00 frames. ], tot_loss[loss=3.346, ArTop10Accuracy=0.7506, NarTop10Accuracy=0.5509, over 1206.31 frames. ], batch size: 3, lr: 3.48e-03, grad_scale: 16.0
2023-11-01 00:52:51,581 INFO [utils.py:877] Clipping_scale=2.0, grad-norm quartiles 2.596e+01 3.632e+01 3.884e+01 4.203e+01 1.192e+02, threshold=7.767e+01, percent-clipped=0.1
2023-11-01 00:53:12,725 INFO [train.py:764] Epoch 1, batch 9100, train_loss[loss=3.108, ArTop10Accuracy=0.745, NarTop10Accuracy=0.6108, over 1255.00 frames. ], tot_loss[loss=3.325, ArTop10Accuracy=0.7506, NarTop10Accuracy=0.5588, over 1204.55 frames. ], batch size: 3, lr: 3.47e-03, grad_scale: 16.0
2023-11-01 00:53:34,455 INFO [train.py:764] Epoch 1, batch 9200, train_loss[loss=3.607, ArTop10Accuracy=0.7313, NarTop10Accuracy=0.4606, over 1243.00 frames. ], tot_loss[loss=3.323, ArTop10Accuracy=0.7512, NarTop10Accuracy=0.559, over 1199.74 frames. ], batch size: 3, lr: 3.46e-03, grad_scale: 16.0
2023-11-01 00:53:56,283 INFO [train.py:764] Epoch 1, batch 9300, train_loss[loss=3.341, ArTop10Accuracy=0.7796, NarTop10Accuracy=0.5181, over 1243.00 frames. ], tot_loss[loss=3.327, ArTop10Accuracy=0.7531, NarTop10Accuracy=0.5566, over 1196.75 frames. ], batch size: 3, lr: 3.44e-03, grad_scale: 16.0
2023-11-01 00:54:18,225 INFO [train.py:764] Epoch 1, batch 9400, train_loss[loss=3.287, ArTop10Accuracy=0.7442, NarTop10Accuracy=0.5898, over 1501.00 frames. ], tot_loss[loss=3.318, ArTop10Accuracy=0.7531, NarTop10Accuracy=0.5604, over 1201.10 frames. ], batch size: 3, lr: 3.43e-03, grad_scale: 16.0
2023-11-01 00:54:40,274 INFO [train.py:764] Epoch 1, batch 9500, train_loss[loss=3.335, ArTop10Accuracy=0.7351, NarTop10Accuracy=0.6181, over 1023.00 frames. ], tot_loss[loss=3.318, ArTop10Accuracy=0.7547, NarTop10Accuracy=0.5604, over 1206.75 frames. ], batch size: 2, lr: 3.41e-03, grad_scale: 16.0
2023-11-01 00:55:02,388 INFO [train.py:764] Epoch 1, batch 9600, train_loss[loss=3.33, ArTop10Accuracy=0.7322, NarTop10Accuracy=0.6035, over 1225.00 frames. ], tot_loss[loss=3.326, ArTop10Accuracy=0.7529, NarTop10Accuracy=0.5581, over 1210.68 frames. ], batch size: 3, lr: 3.40e-03, grad_scale: 16.0
2023-11-01 00:55:24,417 INFO [train.py:764] Epoch 1, batch 9700, train_loss[loss=3.696, ArTop10Accuracy=0.7275, NarTop10Accuracy=0.4242, over 1358.00 frames. ], tot_loss[loss=3.33, ArTop10Accuracy=0.752, NarTop10Accuracy=0.5553, over 1204.10 frames. ], batch size: 3, lr: 3.38e-03, grad_scale: 16.0
2023-11-01 00:55:46,226 INFO [train.py:764] Epoch 1, batch 9800, train_loss[loss=3.352, ArTop10Accuracy=0.7327, NarTop10Accuracy=0.607, over 1025.00 frames. ], tot_loss[loss=3.327, ArTop10Accuracy=0.7526, NarTop10Accuracy=0.5557, over 1201.65 frames. ], batch size: 2, lr: 3.37e-03, grad_scale: 16.0
2023-11-01 00:56:08,325 INFO [train.py:764] Epoch 1, batch 9900, train_loss[loss=3.73, ArTop10Accuracy=0.715, NarTop10Accuracy=0.4577, over 1130.00 frames. ], tot_loss[loss=3.33, ArTop10Accuracy=0.7521, NarTop10Accuracy=0.5557, over 1206.02 frames. ], batch size: 2, lr: 3.36e-03, grad_scale: 16.0
